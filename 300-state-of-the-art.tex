\chapter{State of the art}

\section{Sensor node virtual machines}
Many VMs have been proposed that are small enough to fit on a resource-constrained sensor node. They can be divided into two categories: generic VMs and application-specific VMs, or ASVMs \cite{Culler05} that provide specialised instructions for a specific problem domain. One of the first VMs proposed for sensor networks, Mat\'e \cite{Levis:2002ku}, is an ASVM. It provides single instructions for tasks that are common on a sensor node, so programmes can be very short. Unfortunately they have to be written in a low-level assembly-like language, limiting its target audience. SwissQM \cite{Muller:2007fs} is a more traditional VM, based on a subset of the Java VM, but extended with instructions to access sensors and do data aggregation. VM* \cite{Koshy:2005ww} sits halfway between the generic and ASVM approach. It is a Java VM that can be extended with new features according to application requirements. Unfortunately, it is closed source.

Several generic VMs have also been developed, allowing the programmer to use general purpose languages like Java, Python, or even LISP \cite{Harbaum, Brouwers:2009cj, Aslam:2008, Evers:2010}. The smallest official Java standard is the Connected Device Limited Configuration \cite{CLDC}, but since it targets devices with at least a 16 or 32-bit CPU and 160-512KB of flash memory available, it is still too large for most sensor nodes. The available Java VMs for sensor nodes all offer some subset of the standard Java functionality, occupying different points in the tradeoff between the features they provide, and the resources they require.



\section{Performance}
Only a few papers describing sensor node VMs contain detailed performance measurements. TinyVM \cite{Hong:2009gc} reports a slowdown between 14x and 72x compared to native C, for a set of 9 benchmarks. DVM \cite{Balani:2006} has different versions of the same benchmark, where the fully interpreted version is 108x slower than the fully native version. Ellul reports measurements on the TakaTuka VM \cite{Aslam:2008, Ellul:2012thesis} where the VM is 230x slower than native code, and consumes 150x as much energy. SensorScheme \cite{Evers:2010} is up to 105x slower. Finally, Darjeeling \cite{Brouwers:2009cj} reports between 30x and 113x slowdown. Since performance depends on many factors, it is hard to compare these numbers directly. But the general picture is clear: current interpreters are one to two orders of magnitude slower than native code.

Translating bytecode to native code to improve performance has been a common practice for many years. A wide body of work exists exploring various approaches, either offline, ahead-of-time  or just-in-time. One common offline method is to first translate the Java code to C as an intermediate language, and take advantage of the high quality C compilers available \cite{Muller:1997}. Courbot et al. describe a different approach, where code size is reduced by partly running the application before it is loaded onto the node, allowing them to eliminate code that is only needed during initialisation \cite{Courbot:2010}. Although the initialised objects are translated to C structures that are compiled and linked into a single image, the bytecode is still interpreted. While in general we can produce higher quality code when compiling offline, doing so sacrifices key advantages of using a VM.

Hsieh et al. describe an early ahead-of-time compiling desktop Java VM \cite{Hsieh:1996cy}, focussing on translating the JVM's stack-based architecture to a register based one. In the Japale\~no VM, Alpern et al. take an approach that holds somewhere between AOT and JIT compilation \cite{Alpern:1999}. The VM compiles all code to native code before execution, but can choose from two different compilers to do so. A fast baseline compiler simply mimics the Java stack, but either before or during run-time, a slower optimising compiler may be used to speed up critical methods.

Since JIT compilers work at run-time, much effort has gone into making the compilation process as light weight as possible, for example \cite{Krall:1998}. More recently these efforts have included JIT compilers targeted specifically at embedded devices. Swift \cite{Zhang:2012wf} is a light-weight JVM that improves performance by translating a register-based bytecode to native code. But while the Android devices targeted by Swift may be considered embedded devices, they are still quite powerful and the transformations Swift does are too complex for the ATmega class of devices. HotPathVM \cite{Gal:2006} has lower requirements, but at 150KB for both code and data, this is still an order of magnitude above our target devices.

Given our extreme size constraints - ideally we only want to use in the order of 100 bytes of RAM to allow our approach to be useful on a broad range of devices, and leave ample space for other tasks on the device - almost all AOT and JIT techniques found in literature require too much resources. Indeed, some authors suggest sensor nodes are too restricted to make AOT or JIT compilation feasible \cite{Aslam:2011thesis, Wirjawan:2008}.


% NOTE: the 811\% here comes from the manual optimisation table. since we calculate overhead slightly different there to be able to split it into 3 components, the total in that table is 811 instead of 815 in the trace output text file.
On the desktop, VM performance has been studied extensively, but for sensor node VMs this aspect has been mostly ignored. To the best of our knowledge AOT compilation on a sensor node has only been tried by Ellul and Martinez \cite{Ellul:2010iw}, and our work builds on their approach. They improve performance considerably compared to the interpreters, but there is still much room for improvement. Using the standard CoreMark benchmark, their approach generates code that is 811\% slower and 245\% larger than optimised native C. While the reduced throughput may be acceptable for some applications, there are two other reasons why it is important to improve on these results: the loss of performance results in an equivalent increase in cpu power consumption, thus reducing battery life. More importantly, the increased size of the compiled code reduces the amount of code we can load onto a node. Given that flash memory is already restricted, this is a major sacrifice to make when adopting AOT on sensor nodes.


\section{Safety}
With some exceptions \cite{Evers:2010ur}, most current sensor node VMs don't discuss safety, but instead focus on the functionality provided and how this can be implemented on a tiny sensor node. This is unfortunate, because the ability to provide a safety execution environment is both desirable, and easier to implement using a VM than it is using native code.

For desktop applications, Wahbe et al. described software fault isolation \cite{Wahbe:1994cj} techniques that can be used for situations where we want to isolate a piece of code without incurring the overhead of using processes and the CPU's memory protection. For example, for plugin code that frequently needs to interact with an application, the overhead of frequent context switches, but should still be isolated from the rest of the application. Two basic methods are described: we can either rewrite the native code at load time, and insert checks at all potentially unsafe writes, or we can compile the code to a more restricted format with the appropriate checks already in place, and only verify the code adheres to this standard at load time.

On a sensor node, two systems exist that follow each of these two approaches. \emph{t-kernel} \cite{Gu:2006ww} raises the level of system abstraction for the developer by providing three features typically missing on sensor nodes: preemptive scheduling, virtual memory, and memory protection. It does this by extensive rewriting of the binary code at load time. While \emph{t-kernel} is heavily optimised, the price for this is that programmes still run 50-200\% slower, and code size increases by 500-750\%.

The other approach is taken by Harbor \cite{Kumar:2007ge}, which consists of two components. On the desktop a binary rewriter sandboxes an application by inserting run-time checks before it is sent to the node. Then the SOS operating system is then extended with a binary verifier to verify incoming binaries. The correctness only depends on the correctness of this verifier. The increase in code size is more modest than for \emph{t-kernel} at a 30-65\% increase, but performance is 160-1200\% slower, where the authors note the benchmark producing the 13x slowdown is more typical of sensor node code. They also note more complex analysis of the binary code could reduce the number of necessary checks, but that this would significantly increase the complexity of the verifier.

Finally, Safe TinyOS \cite{Cooprider:2007ub} imposes much less overhead, at 17\% slowdown and 27\% code size increase. It achieves this using Deputy \cite{Condit:2007uo}, a source-to-source compiler for ensuring type and memory safety for C code. The host can do more complex analysis of the source code to reduce the necessary run-time checks. While this protects against bugs, it provides a weaker type of safety because it depends on a trusted host and does not provide safety on the node itself.
