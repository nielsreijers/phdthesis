\section{CoreMark}
\label{sec-evaluation-coremark}

First, we will examine the CoreMark benchmark. CoreMark was developed by the Embedded Microprocessor Benchmark Consortium as a general benchmark for embedded CPUs. It consists of three main parts:
\begin{itemize}
  \item matrix multiplication
  \item a state machine
  \item linked list processing
\end{itemize}

As mentioned before, we kept the Java versions as close to the original C code as possible. The other benchmarks are all relatively simple, and porting them to Java is straightforward. CoreMark is a much more comprehensive benchmark, and the more complex code exposes some challenges when using Java on embedded devices.

The biggest complication is that CoreMark makes extensive use of pointers, which do not exist in Java. In cases where a pointer to a simple variable is passed to a function, we simply wrap it in a wrapper object. A more complicated case is the \mycode{core\_list\_mergesort} function, which takes a function pointer parameter \mycode{cmp} used to compare list elements. Two different implementations exists, \mycode{cmp\_idx} and \mycode{cmp\_complex}. Here we choose the most canonical way to do this in Java, which is to define an interface and pass an object with the right to implementation \mycode{core\_list\_mergesort}.

Finally, the C version of the linked list benchmark takes a block of memory and constructs a linked list inside it by and treating it as \mycode{list\_head} and \mycode{list\_data} structs, shown in Listing \ref{lst-coremark-list-data-structures}. One way to mimic this as closely as possible is to use an array of shorts of equal size to the memory block used in the C version, and use indexes into this array instead of pointers. However this leads to quite messy code.

Instead we choose the more natural Java approach and define two classes to match the structs in C and create instances of these to initialise the list. This is also the faster option because accessing fields is faster than array access. The trade-off is memory consumption, since each object has its own heap header.

\begin{listing}[H]
 \centering
 \begin{minipage}[t]{0.45\textwidth}
  \centering
  \begin{minted}[fontsize=\scriptsize]{c}
typedef struct list_data_s {
    ee_s16 data16;
    ee_s16 idx;
} list_data;

typedef struct list_head_s {
    struct list_head_s *next;
    struct list_data_s *info;
} list_head;
  \end{minted}
 \end{minipage}\hfill
 \begin{minipage}[t]{0.45\textwidth}
  \centering
  \begin{minted}[fontsize=\scriptsize]{java}
public static final class ListData {
    public short data16;
    public short idx;
    }

public static final class ListHead {
    ListHead next;
    ListData info;
}
  \end{minted}
 \end{minipage}
\caption{C and Java version of the CoreMark list data structures}
\label{lst-coremark-list-data-structures}
\end{listing}

\subsection{Manual optimisations}
\label{sec-evaluation-manual-optimisations}
After translating the C to Java code, we only do 'fair' manual optimisations that we believe a future optimising infuser could easily do automatically. Since CoreMark is our most comprehensive benchmark, we use it to evaluate the effect of these manual optimisations.

\input{710-tbl-evaluation-coremark}

Table \ref{tbl-coremark-manual-optimisation} shows the slowdown over the native C version, broken down into CoreMark's three main components. The baseline version, using the original Java code and without using any of our optimisations, is 811\% slower than native C. Even after applying all our other optimisations, the best we can achieve with the original code is a 335\% slowdown, proving the importance of a better optimising infuser.

Next we apply our manual optimisations to the Java source code, as described in Section \ref{sec-optimisations-manual-java-source-optimisation}, and add a small extra optimisation to \mycode{crcu8} which can be easily reorganised to reduce branch overhead.

The effect depends greatly on the characteristics of the code. The matrix part of the benchmark benefits most from using short array indexes, the state machine frequently calls a small method and benefits greatly from inlining it, etc. The reason the linked list part is slightly slower after using short array index variables is that it allocates a small object, and the change in memory usage means this now triggers a run of the garbage collector, which presumably had already happened earlier in the version with int index variables. Combined these optimisations reduce the overhead for the whole benchmark from 335\% to 104\%.

We also applied all these optimisations to the native C version to ensure a fair comparison, but the difference in performance was negligible.

In the rest of the evaluation, all the results presented are for the manually optimised Java code.

\subsection{'Unfair' optimisations}
\label{sec-evaluation-coremark-unfair-optimisations}
After these optimisations, CoreMark is still the slowest of our benchmarks, and the only one to still be at more than 100\% overhead. We can improve performance further if we relax our constraint of only doing optimisations that a compiler could do automatically without changing the code significantly.

In Table \ref{tbl-coremark-manual-optimisation} we see that in the native version, over half of the time is spent in the matrix part of the benchmark, but for the final Java version we see all three parts taking roughly the same time. The state machine and linked list processing both suffer from a much larger slowdown than the matrix part, which by itself would be the second fastest of all our benchmarks.

One of the reasons for the slow performance of the state machine is that it creates two arrays of 8 ints, and an little wrapper object for a short to mimic a C pointer. Allocating memory on the Java heap is much more expensive than it is for a local C variable.

The linked list benchmark also creates a small object, but here the biggest source of overhead is in the virtual method call to the compare objects in \mycode{core\_list\_mergesort} that we use instead of a function pointer. Virtual methods cannot be made lightweight.

This is the best we can do when we strictly translate the C to Java code, and only do optimisations that could be done automatically. If we relax this constraint, we can remove these two sources of overhead as well: because we know we the code will not run multithreaded or recurse, we could choose to statically allocate the small objects used by the state machine, and one by the linked list part, since they only use 90 bytes. The virtual call to the comparer objects in the list benchmark is the most natural implementation this in Java, but given that we know there are only two implementations, we can make both compare methods \mycode{static} and pass a boolean to select which one to call instead of the comparer object. This saves the virtual method call, and allows ProGuard to inline the methods since they are only called from a single location.
% two arrays of 8*32 bits: 64 bytes
% one short wrapper      :  2 bytes
% one ListData           :  4 bytes
% 4*5byte heap header    : 20 bytes

Combined this improves the performance of CoreMark to only 61\% overhead over native C, right in the middle of the spectrum of the other benchmarks. However, the code is now fundamentally different than the original CoreMark, so it is not a completely fair comparison, although a developer writing this code in Java from the start may have made similar choices.

Either way, these results point at some weaknesses of Java when used as an embedded VM. The lack of cheap function pointers, or a way of allocating small local objects or arrays in a method's stack frame means there will be a significant overhead in situations where the optimisations we used here cannot be applied.

Neither of these two optimisations were used in the rest of the evaluation.


















